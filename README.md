# BeyondChats Article Scraper & Rewriter ğŸš€

This project scrapes articles from the **BeyondChats blog**, stores them in MongoDB, provides **CRUD APIs using Node.js + Express**, and includes a **Python-based AI rewriting pipeline** that updates articles using Google-ranked reference content and an LLM (Groq).
A **React frontend** allows users to view original and updated articles and trigger rewrites.

---

## ğŸ§± Tech Stack

| Layer         | Technology                      |
| ------------- | ------------------------------- |
| Scraping      | Python, Requests, BeautifulSoup |
| Backend APIs  | Node.js, Express                |
| Database      | MongoDB Atlas                   |
| AI / LLM      | Groq API                        |
| Search        | SERP API (Google Search)        |
| Frontend      | ReactJS                         |
| Orchestration | Node â†’ Python via child_process |

---

## ğŸ“‚ Project Structure

```
BeyondChats/
â”‚
â”œâ”€â”€ backend/                # Node + Express APIs
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ articles.js
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ Article.js
â”‚   â””â”€â”€ index.js
|   â”œâ”€â”€ scraper/                  # Python scraping & rewriting
â”‚         â””â”€â”€ index.py            # main rewrite pipeline
â”‚         â””â”€â”€ scrape.py           # BeyondChats scraper
â”‚         â””â”€â”€ google_search.py    # SERP API logic
â”‚         â””â”€â”€ scrape_article.py   # external article scraper
â”‚         â””â”€â”€ llm_rewrite.py      # Groq LLM logic
â”‚         â””â”€â”€ config.py           # For all API keys
â”‚
â”œâ”€â”€ frontend/               # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticleList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FullArticle.jsx
â”‚   â”‚   â”‚   â””â”€â”€ FullCard.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Home.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Loader.jsx
â”‚   â”‚   â”‚   â””â”€â”€ MarkdownRenderer.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Tabs.jsx
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚
â””â”€â”€ README.md
```

---


## âš™ï¸ Live (Hosted URL) 

```bash
https://scarp-writing.netlify.app/
```





## âš™ï¸ Local Setup Instructions

###  Clone Repository

```bash
git clone https://github.com/SG17THEProgrammer/BeyondChats-Article-Scraper-Rewriter.git

```



###  Backend Setup (Node.js)

```bash
cd backend
npm install
npm start
```

Backend runs on:

```
http://localhost:5000
```

---

### 4ï¸âƒ£ Python Scraper & Rewriter Setup

```bash
cd scraper
pip install -r requirements.txt
```

Add `.env`:

```env
MONGO_URI=your_mongo_uri
GROQ_API_KEY=your_groq_key
SERP_API_KEY=your_serpapi_key
GROQ_MODEL=your_groq_model
```

Run initial scraper to scrap "Beyond Chats Website":

```bash
python scrape.py
```

---

### 5ï¸âƒ£ Frontend Setup (React)

```bash
cd frontend
npm install
npm run dev
```

Frontend runs on:

```
http://localhost:3000
```

---

## ğŸ” Data Flow / Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Frontend          â”‚
â”‚      (ReactJS App)       â”‚
â”‚                          â”‚
â”‚ â€¢ View article list both â”‚
â”‚  original and updated    â”‚
â”‚ â€¢ View full article      â”‚
â”‚ â€¢ Trigger rewrite action â”‚
â”‚ â€¢ Show loading & status  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ REST APIs (HTTP/JSON)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Backend API       â”‚
â”‚     (Node.js + Express)  â”‚
â”‚                          â”‚
â”‚ â€¢ Article CRUD APIs      â”‚
â”‚ â€¢ Rewrite trigger route  â”‚
â”‚ â€¢ Python process spawn   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ spawn() / child_process
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Processing Layer    â”‚
â”‚        (Python)          â”‚
â”‚                          â”‚
â”‚ 1. Fetch article by ID   â”‚
â”‚ 2. Perform SERP search   â”‚
â”‚ 3. Scrape top references â”‚
â”‚ 4. Rewrite using Groq    â”‚
â”‚    LLM (Markdown output) â”‚
â”‚ 5. Store rewritten data â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Database Operations
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Database        â”‚
â”‚          (MongoDB)       â”‚
â”‚                          â”‚
â”‚ â€¢ Original articles      â”‚
â”‚ â€¢ Rewritten articles     â”‚
â”‚ â€¢ References             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ğŸ§  Rewrite Pipeline

1. User selects an article from frontend
2. Frontend calls:

   ```
   POST /api/articles/:id/rewrite
   ```
3. Backend:

   * Spawns Python script
     
5. Python script:

   * Searches article title on Google
   * Filters repetitve/unscrappable  links
   * Scrapes content from top 2 articles (if possible and available)
   * Uses Groq LLM to rewrite content
   * Stores updated article with references
     
6. Backend updates
   
7. Frontend accordingly updates the UI

---

## ğŸ“Œ How Updated Articles Are Identified

An article is considered **updated** if :

* Title ends with `(Updated)`

No separate endpoint required.

---

## ğŸ¯ Features

* âœ… Scrape oldest BeyondChats articles
* âœ… Store full content in MongoDB
* âœ… Rewrite using Google-ranked articles
* âœ… LLM-based content enhancement
* âœ… Reference citation
* âœ… Responsive React UI
* âœ… Markdown rendering support

---


âš ï¸ Important Notes & Limitations

ğŸ”’ Access Restrictions
Some websites block automated scraping (403 / Access Denied). In such cases, only 1 reference article may be available instead of 2.

â˜ï¸ Render Hosting Constraints
The backend runs on Render, and many sites restrict cloud IPs â€” this can lead to fewer scrapeable sources.

â³ Performance Delay
Scraping + rewriting is a background-heavy task. On Render, it may take slightly longer due to cold starts & limited resources.

ğŸ’» Local vs Production

Running locally:
Faster execution âš¡
Higher success rate for 2 or more  references âœ…

ğŸ¯ Intentional Design Choice
No paid proxies used â€” kept cost-efficient, simple, and transparent.

